ModelConfigs(
  llama270b: (
    temperature: 1, 
    p: 0.1,
    max_gen_len: 1024,
  ),
  cohere_command:(
      max_tokens: 500,
      temperature: 1.0,
      p: 0.1,
      k: 1,
      stop_sequences: [],
      stream: true,
  ),
  claude_v2:(
      temperature: 1.0,
      p: 1.0,
      k: 250,
      max_tokens_to_sample: 500,
      stop_sequences: [],
  ),
  claude_v21:(
      temperature: 1.0,
      p: 1.0,
      k: 250,
      max_tokens_to_sample: 500,
      stop_sequences: [],
  ),
  jurrasic_2_ultra:(
      temperature: 0.7,
      top_p: 1,
      max_tokens: 200,
      stop_sequences: [],
  ),
  titan_text_express_v1:(
      temperature: 0,
      top_p: 1,
      max_token_count: 8192,
      stop_sequences: [],
  )
)
